{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyxDBbz7Di41Rd0LG5/qKP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/butyusya/project_lbacn/blob/main/crawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/butyusya/project_lbacn.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SWwIVCAZ6IW",
        "outputId": "2147ba08-eb6b-4b54-e117-52805950e331"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'project_lbacn'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fake_useragent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v69WfaxEbh8G",
        "outputId": "cf9798c6-eb0b-4bb8-a6d8-c83bb123769e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fake_useragent\n",
            "  Downloading fake_useragent-1.4.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: fake_useragent\n",
            "Successfully installed fake_useragent-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from fake_useragent import UserAgent\n",
        "from bs4 import BeautifulSoup\n",
        "import re"
      ],
      "metadata": {
        "id": "26oGHC6MvTNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ua = UserAgent()\n",
        "headers = {'User-Agent': ua.random}\n",
        "session = requests.session()"
      ],
      "metadata": {
        "id": "Xsb0--T_vdol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_episode(episode):\n",
        "  block = {}\n",
        "  info = episode.find_all('td')\n",
        "  id = info[4].text.strip()\n",
        "  block['ep_id'] = int(re.sub(r'\\[\\d+\\]', '', id))\n",
        "  block['ep_href'] = info[2].find('a').attrs['href']\n",
        "  block['ep_title'] = info[2].find('a').text\n",
        "  return block"
      ],
      "metadata": {
        "id": "jqDAmLrh4j3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_episode_info(block):\n",
        "  url = 'https://miraculousladybug.fandom.com' + block['ep_href']\n",
        "  req = session.get(url, headers={'User-Agent': ua.random})\n",
        "  body = req.text\n",
        "  text = body.split('Synopsis</span>')[2]\n",
        "  first_div = text.split('<span class=\"mw-headline\" id=\"Plot\">Plot</span>')\n",
        "  syn = first_div[0]\n",
        "  porridge = BeautifulSoup(syn, 'html.parser')\n",
        "  synopsis = porridge.find('p').text.strip()\n",
        "  block['synopsis'] = re.sub(r'\\[\\d+\\]', '', synopsis)\n",
        "  other = first_div[1]\n",
        "  second_div = other.split('<h2>')\n",
        "  pl = second_div[0]\n",
        "  porridge = BeautifulSoup(pl, 'html.parser')\n",
        "  pl_pars = porridge.find_all('p')\n",
        "  plot = ''\n",
        "  for p in pl_pars:\n",
        "    plot += p.text\n",
        "  block['plot'] = re.sub(r'\\[\\d+\\]', '', plot)\n",
        "  url_scr = 'https://miraculousladybug.fandom.com' + block['ep_href']+ '/Transcript'\n",
        "  req = session.get(url_scr, headers={'User-Agent': ua.random})\n",
        "  body = req.text\n",
        "  script = body.split('</td></tr></tbody></table></center>')[1].split('THE END')[0]\n",
        "  porridge = BeautifulSoup(script, 'html.parser')\n",
        "  block['script'] = porridge.text.replace('[ Theme Song ]', '').replace('[ Theme song ]', '').strip()\n",
        "  return block"
      ],
      "metadata": {
        "id": "8A6CsffoT0Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_season(table, blocks):\n",
        "  episodes = table.find_all('tr')\n",
        "  for n in range(1, len(episodes)):\n",
        "    try:\n",
        "      block = parse_episode(episodes[n])\n",
        "    except Exception as e:\n",
        "      print(1, e, i, n)\n",
        "    try:\n",
        "      parse_episode_info(block)\n",
        "    except Exception as e:\n",
        "      print(2, e, i, n)\n",
        "    try:\n",
        "      blocks.append(block)\n",
        "    except Exception as e:\n",
        "      print(3, e, i, n)\n",
        "  return blocks"
      ],
      "metadata": {
        "id": "jAhKfPwI7DXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blocks = []\n",
        "for i in range(1, 6):\n",
        "  url_one = 'https://miraculousladybug.fandom.com/wiki/Season_' + str(i)\n",
        "  req = session.get(url_one, headers={'User-Agent': ua.random})\n",
        "  body = req.text\n",
        "  soup = BeautifulSoup(body, 'html.parser')\n",
        "  tables = soup.find_all('table')\n",
        "  table = tables[4]\n",
        "  parse_season(table, blocks)"
      ],
      "metadata": {
        "id": "4P1EmV-rJBr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b3c1c6e-3ce0-4210-b70c-2a766904ce26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 ('Connection broken: IncompleteRead(3911680 bytes read, 1032338 more expected)', IncompleteRead(3911680 bytes read, 1032338 more expected)) 4 3\n",
            "2 ('Connection broken: IncompleteRead(3780608 bytes read, 505786 more expected)', IncompleteRead(3780608 bytes read, 505786 more expected)) 4 14\n",
            "2 ('Connection broken: IncompleteRead(3219456 bytes read, 1662788 more expected)', IncompleteRead(3219456 bytes read, 1662788 more expected)) 4 21\n",
            "2 ('Connection broken: IncompleteRead(2965504 bytes read, 1718991 more expected)', IncompleteRead(2965504 bytes read, 1718991 more expected)) 5 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_table_query = \"\"\"\n",
        "CREATE TABLE episodes (\n",
        "    ep_id INT,\n",
        "    ep_href TEXT,\n",
        "    ep_title TEXT,\n",
        "    synopsis TEXT,\n",
        "    plot TEXT,\n",
        "    script TEXT,\n",
        "    PRIMARY KEY (ep_id)\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "HwXwD60vJ2_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "con = sqlite3.connect('lbacn.db')\n",
        "cur = con.cursor()\n",
        "cur.execute(new_table_query)\n",
        "con.commit()"
      ],
      "metadata": {
        "id": "WiPL6lc9JjOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for block in blocks:\n",
        "  cur.execute(\"INSERT INTO episodes VALUES (:ep_id, :ep_href, :ep_title, :synopsis, :plot, :script)\", block)\n",
        "con.commit()"
      ],
      "metadata": {
        "id": "ULpEcCcVK6H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image(block):\n",
        "  url = 'https://miraculousladybug.fandom.com' + block['ep_href']\n",
        "  req = session.get(url, headers={'User-Agent': ua.random})\n",
        "  body = req.text\n",
        "  porridge = BeautifulSoup(body, 'html.parser')\n",
        "  image_info = porridge.find('figure', {'class': 'pi-item pi-image'})\n",
        "  image_url = image_info.find('a').attrs['href']\n",
        "  img_data = requests.get(image_url).content\n",
        "  with open('project_lbacn/static/'+str(block['ep_id'])+'.png', 'wb') as handler:\n",
        "    handler.write(img_data)"
      ],
      "metadata": {
        "id": "HmKQJti69JEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for b in blocks:\n",
        "  try:\n",
        "    get_image(b)\n",
        "  except Exception as e:\n",
        "    print(b['ep_id'])"
      ],
      "metadata": {
        "id": "o812fVcU87RX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}